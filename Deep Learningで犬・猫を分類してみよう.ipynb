{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Academy_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3sjsR2qDGm8",
        "outputId": "415209d5-0436-4e76-9c8d-19292e644269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# https://aiacademy.jp/texts/show/?id=164\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 312 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0 requires keras<2.8,>=2.7.0rc0, but you have keras 2.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.2.4 keras-applications-1.0.8\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.13.3)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.42.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EcfPhx7DJyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cdc455-26f4-4d7d-99e5-2ad1da7e759b"
      },
      "source": [
        "import tensorflow as tf \n",
        "import keras \n",
        "\n",
        "print(tf.__version__);\n",
        "print(keras.__version__);"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.0\n",
            "2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ランタイムからGPUに変更"
      ],
      "metadata": {
        "id": "kLRxGJomN8mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icrawler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDNS9sJ2N3ix",
        "outputId": "06a14e18-88b1-456a-8c5b-d66e3fc5aafb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.6-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from icrawler) (7.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from icrawler) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from icrawler) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from icrawler) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from icrawler) (4.2.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->icrawler) (2021.10.8)\n",
            "Installing collected packages: icrawler\n",
            "Successfully installed icrawler-0.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# 猫の画像を100枚取得\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"cat\"})\n",
        "crawler.crawl(keyword=\"猫\", max_num=40)"
      ],
      "metadata": {
        "id": "lpVj_n4WOCwa",
        "outputId": "bd48c2ed-1b29-4c81-f8bc-70b8f3f6d4fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-25 06:19:16,378 - INFO - icrawler.crawler - start crawling...\n",
            "2021-12-25 06:19:16,388 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
            "2021-12-25 06:19:16,392 - INFO - feeder - thread feeder-001 exit\n",
            "2021-12-25 06:19:16,395 - INFO - icrawler.crawler - starting 1 parser threads...\n",
            "2021-12-25 06:19:16,427 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
            "2021-12-25 06:19:16,792 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=0\n",
            "2021-12-25 06:19:16,924 - INFO - downloader - skip downloading file 000001.jpg\n",
            "2021-12-25 06:19:16,932 - INFO - downloader - skip downloading file 000002.jpg\n",
            "2021-12-25 06:19:16,937 - INFO - downloader - skip downloading file 000003.jpg\n",
            "2021-12-25 06:19:16,939 - INFO - downloader - skip downloading file 000004.jpg\n",
            "2021-12-25 06:19:16,943 - INFO - downloader - skip downloading file 000005.jpg\n",
            "2021-12-25 06:19:16,948 - INFO - downloader - skip downloading file 000006.jpg\n",
            "2021-12-25 06:19:16,953 - INFO - downloader - skip downloading file 000007.jpg\n",
            "2021-12-25 06:19:16,960 - INFO - downloader - skip downloading file 000008.jpg\n",
            "2021-12-25 06:19:16,968 - INFO - downloader - skip downloading file 000009.jpg\n",
            "2021-12-25 06:19:16,969 - INFO - downloader - skip downloading file 000010.jpg\n",
            "2021-12-25 06:19:16,979 - INFO - downloader - skip downloading file 000011.jpg\n",
            "2021-12-25 06:19:16,983 - INFO - downloader - skip downloading file 000012.jpg\n",
            "2021-12-25 06:19:16,990 - INFO - downloader - skip downloading file 000013.jpg\n",
            "2021-12-25 06:19:16,996 - INFO - downloader - skip downloading file 000014.jpg\n",
            "2021-12-25 06:19:17,003 - INFO - downloader - skip downloading file 000015.jpg\n",
            "2021-12-25 06:19:17,008 - INFO - downloader - skip downloading file 000016.jpg\n",
            "2021-12-25 06:19:17,014 - INFO - downloader - skip downloading file 000017.jpg\n",
            "2021-12-25 06:19:17,019 - INFO - downloader - skip downloading file 000018.jpg\n",
            "2021-12-25 06:19:17,024 - INFO - downloader - skip downloading file 000019.jpg\n",
            "2021-12-25 06:19:17,029 - INFO - downloader - skip downloading file 000020.jpg\n",
            "2021-12-25 06:19:19,886 - INFO - downloader - image #21\thttps://img.zcool.cn/community/01e3485ce75412a801214168066c47.jpg\n",
            "2021-12-25 06:19:21,197 - INFO - downloader - image #22\thttps://img.zcool.cn/community/01d46f5ccb2c28a801214168a4fad2.jpg\n",
            "2021-12-25 06:19:22,717 - INFO - downloader - image #23\thttps://img.zcool.cn/community/0188d45cc949e2a8012141688f6e34.jpg\n",
            "2021-12-25 06:19:23,523 - INFO - downloader - image #24\thttps://pic2.zhimg.com/v2-372b62c4d6bcdd982ad8308e02c40491_r.jpg\n",
            "2021-12-25 06:19:25,751 - INFO - downloader - image #25\thttps://img.zcool.cn/community/01d01e5568d24b0000012716c3ea7f.jpg\n",
            "2021-12-25 06:19:26,007 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=20\n",
            "2021-12-25 06:19:26,225 - INFO - downloader - image #26\thttps://img.zcool.cn/community/01c0665543065f0000019ae92d2f01.jpg\n",
            "2021-12-25 06:19:27,104 - INFO - downloader - image #27\thttps://img.zcool.cn/community/016aad5d65f133a80120695c124d2e.jpg\n",
            "2021-12-25 06:19:27,676 - INFO - downloader - image #28\thttps://pic1.zhimg.com/v2-b263d820597306d3505563a5746e0cae_r.jpg\n",
            "2021-12-25 06:19:28,008 - INFO - downloader - image #29\thttps://pic4.zhimg.com/v2-ae9128beadc9a6121d50bbfa87d1d44d_r.jpg\n",
            "2021-12-25 06:19:28,049 - INFO - downloader - image #30\thttps://pic4.zhimg.com/v2-9eeeaa3f0a8d582f5d0833082e615fef_r.jpg\n",
            "2021-12-25 06:19:30,104 - INFO - downloader - image #31\thttp://pc.chuangyezong.com/data/file/20200104/2020010482130.jpg\n",
            "2021-12-25 06:19:32,253 - INFO - downloader - image #32\thttps://img.zcool.cn/community/01d3a15ce78b6aa80121a470fc0081.jpg\n",
            "2021-12-25 06:19:32,911 - INFO - downloader - image #33\thttps://img.zcool.cn/community/01bc685ce750dda801208f8bed54ec.jpg\n",
            "2021-12-25 06:19:33,785 - INFO - downloader - image #34\thttps://img.zcool.cn/community/0131985568d24b00000127169a4b4e.jpg\n",
            "2021-12-25 06:19:33,832 - INFO - downloader - image #35\thttps://pic4.zhimg.com/v2-1fe7d9c7bb8d2c1d3e80fa33bfaa7037_r.jpg\n",
            "2021-12-25 06:19:33,961 - INFO - downloader - image #36\thttps://pic1.zhimg.com/v2-58d3be512275aa1c7e458dfea4d0142b_r.jpg\n",
            "2021-12-25 06:19:34,624 - INFO - downloader - image #37\thttps://img.zcool.cn/community/01a44d5d3920a2a80120695cfbe450.jpg\n",
            "2021-12-25 06:19:34,923 - INFO - downloader - image #38\thttps://pic2.zhimg.com/v2-97e9033a5f017ddfe3fc1633d8cb1a0d_r.jpg\n",
            "2021-12-25 06:19:35,793 - INFO - downloader - image #39\thttps://img.zcool.cn/community/0145d05d565d36a80120695cb7da64.jpg\n",
            "2021-12-25 06:19:35,980 - INFO - downloader - image #40\thttps://pic2.zhimg.com/dbc574a17ebfce1747a0ec36cb0c25c6_r.jpg\n",
            "2021-12-25 06:19:36,003 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
            "2021-12-25 06:19:36,005 - INFO - downloader - thread downloader-001 exit\n",
            "2021-12-25 06:19:36,456 - INFO - icrawler.crawler - Crawling task done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# 猫の画像を100枚取得\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"dog\"})\n",
        "crawler.crawl(keyword=\"犬\", max_num=40)"
      ],
      "metadata": {
        "id": "YuQSzaqcOFo2",
        "outputId": "89670c15-f230-4173-8f63-7ba649d55c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-25 06:19:48,041 - INFO - icrawler.crawler - start crawling...\n",
            "2021-12-25 06:19:48,044 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
            "2021-12-25 06:19:48,048 - INFO - feeder - thread feeder-001 exit\n",
            "2021-12-25 06:19:48,052 - INFO - icrawler.crawler - starting 1 parser threads...\n",
            "2021-12-25 06:19:48,057 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
            "2021-12-25 06:19:48,426 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=0\n",
            "2021-12-25 06:19:48,450 - INFO - downloader - skip downloading file 000001.jpg\n",
            "2021-12-25 06:19:48,454 - INFO - downloader - skip downloading file 000002.jpg\n",
            "2021-12-25 06:19:48,457 - INFO - downloader - skip downloading file 000003.jpg\n",
            "2021-12-25 06:19:48,460 - INFO - downloader - skip downloading file 000004.jpg\n",
            "2021-12-25 06:19:48,462 - INFO - downloader - skip downloading file 000005.jpg\n",
            "2021-12-25 06:19:48,464 - INFO - downloader - skip downloading file 000006.jpg\n",
            "2021-12-25 06:19:48,466 - INFO - downloader - skip downloading file 000007.jpg\n",
            "2021-12-25 06:19:48,469 - INFO - downloader - skip downloading file 000008.jpg\n",
            "2021-12-25 06:19:48,471 - INFO - downloader - skip downloading file 000009.jpg\n",
            "2021-12-25 06:19:48,473 - INFO - downloader - skip downloading file 000010.jpg\n",
            "2021-12-25 06:19:48,475 - INFO - downloader - skip downloading file 000011.jpg\n",
            "2021-12-25 06:19:48,478 - INFO - downloader - skip downloading file 000012.jpg\n",
            "2021-12-25 06:19:48,479 - INFO - downloader - skip downloading file 000013.jpg\n",
            "2021-12-25 06:19:48,482 - INFO - downloader - skip downloading file 000014.jpg\n",
            "2021-12-25 06:19:48,483 - INFO - downloader - skip downloading file 000015.jpg\n",
            "2021-12-25 06:19:48,486 - INFO - downloader - skip downloading file 000016.jpg\n",
            "2021-12-25 06:19:48,487 - INFO - downloader - skip downloading file 000017.jpg\n",
            "2021-12-25 06:19:48,493 - INFO - downloader - skip downloading file 000018.jpg\n",
            "2021-12-25 06:19:48,494 - INFO - downloader - skip downloading file 000019.jpg\n",
            "2021-12-25 06:19:48,497 - INFO - downloader - skip downloading file 000020.jpg\n",
            "2021-12-25 06:19:53,766 - ERROR - downloader - Exception caught when downloading file https://www.ana.co.jp/domtour/area/akita/assets/img/page/img_main_akita_dog_pc.jpg, error: HTTPSConnectionPool(host='www.ana.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n",
            "2021-12-25 06:19:58,751 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=20\n",
            "2021-12-25 06:19:59,060 - ERROR - downloader - Exception caught when downloading file https://www.ana.co.jp/domtour/area/akita/assets/img/page/img_main_akita_dog_pc.jpg, error: HTTPSConnectionPool(host='www.ana.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 1\n",
            "2021-12-25 06:20:04,310 - ERROR - downloader - Exception caught when downloading file https://www.ana.co.jp/domtour/area/akita/assets/img/page/img_main_akita_dog_pc.jpg, error: HTTPSConnectionPool(host='www.ana.co.jp', port=443): Read timed out. (read timeout=5), remaining retry times: 0\n",
            "2021-12-25 06:20:04,334 - INFO - downloader - image #21\thttps://1.bp.blogspot.com/-LmmkeFy607Y/WrD1GfzHAKI/AAAAAAAAF_c/hDdmR33XaGg01i9R6HocUMlAcSljwv5dQCLcBGAs/w1200-h630-p-k-no-nu/Rigeru1.jpg\n",
            "2021-12-25 06:20:04,376 - INFO - downloader - image #22\thttps://3.bp.blogspot.com/-IIsg4v83D6c/WrD1GWqpEzI/AAAAAAAAF_k/6BgrOdJKfCMlWzzRg4WhLM1UZh3bfbk9gCLcBGAs/s1600/Rigeru3.jpg\n",
            "2021-12-25 06:20:05,892 - INFO - downloader - image #23\thttps://qpet.jp/dog/wp-content/uploads/2017/07/143-i-685x1024.jpg\n",
            "2021-12-25 06:20:05,972 - INFO - downloader - image #24\thttp://stat.ameba.jp/user_images/20160828/18/d1gp-takayama/49/09/j/o0740049313734425836.jpg\n",
            "2021-12-25 06:20:06,304 - INFO - downloader - image #25\thttps://akita.min-breeder.com/breeder/data/hachikotakasaki/dog_img_1_954ca99c40f3.jpg\n",
            "2021-12-25 06:20:06,841 - INFO - downloader - image #26\thttp://mydognatsu.cocolog-nifty.com/photos/uncategorized/2009/04/14/0412_776.jpg\n",
            "2021-12-25 06:20:07,987 - INFO - downloader - image #27\thttps://media.dogpad.jp/dogpad_media/wp-content/uploads/2021/01/2023814_m.jpg\n",
            "2021-12-25 06:20:08,254 - INFO - downloader - image #28\thttp://blogimg.goo.ne.jp/user_image/71/95/cca226e5edd3169b6a2c9551cba6b23b.jpg\n",
            "2021-12-25 06:20:08,277 - INFO - downloader - image #29\thttp://blogimg.goo.ne.jp/user_image/37/6d/cf91e0611b1a62dfaa26fa9c75638e63.jpg\n",
            "2021-12-25 06:20:09,541 - INFO - downloader - image #30\thttps://dognoie.com/blog/_dog-picturebook/wp-content/uploads/sites/56/2018/07/7c984d3c0f2b9646a8320cb85a58c792_m-1.jpg\n",
            "2021-12-25 06:20:09,566 - INFO - downloader - image #31\thttp://blogimg.goo.ne.jp/user_image/0c/20/77ed79d3f58092c25cf6c500553226c1.jpg\n",
            "2021-12-25 06:20:09,586 - INFO - downloader - image #32\thttp://blogimg.goo.ne.jp/user_image/03/2d/c4826f3e7966edc325b7cb647e9563ff.jpg\n",
            "2021-12-25 06:20:11,576 - INFO - downloader - image #33\thttp://www.worldranch.co.jp/dog_corner/images/yamato_01.jpg\n",
            "2021-12-25 06:20:12,133 - INFO - downloader - image #34\thttp://livedoor.blogimg.jp/enngawa_de_ohirune/imgs/3/0/306f5cc7.jpg\n",
            "2021-12-25 06:20:12,154 - INFO - downloader - image #35\thttp://blogimg.goo.ne.jp/user_image/0f/dc/34067d0eced8f72fdcc40c977249b4ea.jpg\n",
            "2021-12-25 06:20:13,594 - INFO - parser - no more page urls for thread parser-001 to parse\n",
            "2021-12-25 06:20:13,596 - INFO - parser - thread parser-001 exit\n",
            "2021-12-25 06:20:14,906 - INFO - downloader - image #36\thttps://www.inutome.jp/c/wp-content/uploads/2018/05/pixta_39330811_M.jpg\n",
            "2021-12-25 06:20:15,723 - INFO - downloader - image #37\thttps://cdn.wanchan.jp/c/wanchan.jp/pro/resize/400x400/100/7/30b3e566949618a64e9a9c861ee62b47.jpg\n",
            "2021-12-25 06:20:17,028 - INFO - downloader - image #38\thttps://qpet.jp/dog/wp-content/uploads/2017/06/142-4.jpg\n",
            "2021-12-25 06:20:22,031 - INFO - downloader - no more download task for thread downloader-001\n",
            "2021-12-25 06:20:22,033 - INFO - downloader - thread downloader-001 exit\n",
            "2021-12-25 06:20:22,095 - INFO - icrawler.crawler - Crawling task done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "# IOError: image file is truncated (0 bytes not processed)回避のため\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "classes = [\"dog\", \"cat\"]\n",
        "num_classes = len(classes)\n",
        "image_size = 64\n",
        "num_testdata = 25\n",
        "\n",
        "X_train = []\n",
        "X_test  = []\n",
        "y_train = []\n",
        "y_test  = []\n",
        "\n",
        "for index, classlabel in enumerate(classes):\n",
        "    photos_dir = \"./\" + classlabel\n",
        "    files = glob.glob(photos_dir + \"/*.jpg\")\n",
        "    for i, file in enumerate(files):\n",
        "        image = Image.open(file)\n",
        "        image = image.convert(\"RGB\")\n",
        "        image = image.resize((image_size, image_size))\n",
        "        data = np.asarray(image)\n",
        "        if i < num_testdata:\n",
        "            X_test.append(data)\n",
        "            y_test.append(index)\n",
        "        else:\n",
        "\n",
        "            # angleに代入される値\n",
        "            # -20\n",
        "            # -15\n",
        "            # -10\n",
        "            #  -5\n",
        "            # 0\n",
        "            # 5\n",
        "            # 10\n",
        "            # 15\n",
        "            # 画像を5度ずつ回転\n",
        "            for angle in range(-20, 20, 5):\n",
        "\n",
        "                img_r = image.rotate(angle)\n",
        "                data = np.asarray(img_r)\n",
        "                X_train.append(data)\n",
        "                y_train.append(index)\n",
        "                # FLIP_LEFT_RIGHT　は 左右反転\n",
        "                img_trains = img_r.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                data = np.asarray(img_trains)\n",
        "                X_train.append(data)\n",
        "                y_train.append(index)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test  = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test  = np.array(y_test)\n",
        "\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"./dog_cat.npy\", xy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_wB90AyOKFN",
        "outputId": "0baae77e-2f3b-4051-e199-ef44c75a67c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "optimizers.RMSprop\n",
        "optimizers.Adam\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "classes = [\"dog\", \"cat\"]\n",
        "num_classes = len(classes)\n",
        "image_size = 64\n",
        "\n",
        "\"\"\"\n",
        "データを読み込む関数\n",
        "\"\"\"\n",
        "def load_data():\n",
        "    X_train, X_test, y_train, y_test = np.load(\"./dog_cat.npy\", allow_pickle=True)\n",
        "    # 入力データの各画素値を0-1の範囲で正規化(学習コストを下げるため)\n",
        "    X_train = X_train.astype(\"float\") / 255\n",
        "    X_test  = X_test.astype(\"float\") / 255\n",
        "    # to_categorical()にてラベルをone hot vector化\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test  = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\"\"\"\n",
        "モデルを学習する関数\n",
        "\"\"\"\n",
        "def train(X, y, X_test, y_test):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Xは(1200, 64, 64, 3)\n",
        "    # X.shape[1:]とすることで、(64, 64, 3)となり、入力にすることが可能です。\n",
        "    model.add(Conv2D(32,(3,3), padding='same',input_shape=X.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32,(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64,(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.45))\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # https://keras.io/ja/optimizers/\n",
        "    # 今回は、最適化アルゴリズムにRMSpropを利用\n",
        "    opt = RMSprop(lr=0.00005, decay=1e-6)\n",
        "    # https://keras.io/ja/models/sequential/\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X, y, batch_size=28, epochs=40)\n",
        "    # HDF5ファイルにKerasのモデルを保存\n",
        "    model.save('./cnn.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "メイン関数\n",
        "データの読み込みとモデルの学習を行います。\n",
        "\"\"\"\n",
        "def main():\n",
        "    # データの読み込み\n",
        "    X_train, y_train, X_test, y_test = load_data()\n",
        "\n",
        "    # モデルの学習\n",
        "    model = train(X_train, y_train, X_test, y_test)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "__a2oHOyOQmP",
        "outputId": "3ace119e-6053-4b90-d9d8-956d8eb97445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "16/16 [==============================] - 10s 38ms/step - loss: 0.6886 - accuracy: 0.5603\n",
            "Epoch 2/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.6540 - accuracy: 0.6317\n",
            "Epoch 3/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.6309 - accuracy: 0.6942\n",
            "Epoch 4/40\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.5756 - accuracy: 0.7500\n",
            "Epoch 5/40\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.5039 - accuracy: 0.8571\n",
            "Epoch 6/40\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.4732 - accuracy: 0.8259\n",
            "Epoch 7/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.4073 - accuracy: 0.8571\n",
            "Epoch 8/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.3352 - accuracy: 0.9085\n",
            "Epoch 9/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.3205 - accuracy: 0.8906\n",
            "Epoch 10/40\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.2555 - accuracy: 0.9576\n",
            "Epoch 11/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.2208 - accuracy: 0.9464\n",
            "Epoch 12/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.1725 - accuracy: 0.9710\n",
            "Epoch 13/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.1683 - accuracy: 0.9643\n",
            "Epoch 14/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.1657 - accuracy: 0.9531\n",
            "Epoch 15/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.1367 - accuracy: 0.9710\n",
            "Epoch 16/40\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1108 - accuracy: 0.9799\n",
            "Epoch 17/40\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0859 - accuracy: 0.9933\n",
            "Epoch 18/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0815 - accuracy: 0.9866\n",
            "Epoch 19/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0851 - accuracy: 0.9821\n",
            "Epoch 20/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0548 - accuracy: 0.9911\n",
            "Epoch 21/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0578 - accuracy: 0.9866\n",
            "Epoch 22/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0415 - accuracy: 0.9978\n",
            "Epoch 23/40\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0542 - accuracy: 0.9911\n",
            "Epoch 24/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 25/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0256 - accuracy: 0.9955\n",
            "Epoch 26/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0531 - accuracy: 0.9888\n",
            "Epoch 27/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 28/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0195 - accuracy: 0.9978\n",
            "Epoch 29/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 30/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 31/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 32/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 33/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0375 - accuracy: 0.9888\n",
            "Epoch 34/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 35/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 36/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0392 - accuracy: 0.9844\n",
            "Epoch 37/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 38/40\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 39/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 40/40\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0207 - accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dog1.jpg のファイル名で犬の画像をアップロードする(下記コマンドでダウンロード)\n",
        "!wget -O \"dog1.jpg\" https://aiacademy.jp/assets/images_test/164_16bd5895d6f.jpeg "
      ],
      "metadata": {
        "id": "Zo8_yH2bOUMa",
        "outputId": "cbaed551-e609-4c8e-a98a-bfe4325ebd35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-25 06:26:51--  https://aiacademy.jp/assets/images_test/164_16bd5895d6f.jpeg\n",
            "Resolving aiacademy.jp (aiacademy.jp)... 54.150.165.60\n",
            "Connecting to aiacademy.jp (aiacademy.jp)|54.150.165.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28306 (28K) [image/jpeg]\n",
            "Saving to: ‘dog1.jpg’\n",
            "\n",
            "dog1.jpg            100%[===================>]  27.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-25 06:26:52 (202 MB/s) - ‘dog1.jpg’ saved [28306/28306]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import sys, os\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "imsize = (64, 64)\n",
        "\n",
        "\"\"\"\n",
        "dog1.jpgというファイル名の画像をGoogle Colab上にアップロードする方法は2通りあります。\n",
        "1つが、下記のコードを実行し画像をアップロードする方法\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "2つが、Colab左メニューの>アイコンを押して、目次、コード スニペット、ファイル\n",
        "の3つ表示されるますが、右のファイルタブから画像をアップロードする方法です。\n",
        "このファイルタブをクリックするとアップロードと更新の2つがありますが、\n",
        "アップロードを押すと画像をアップロードすることが可能です。\n",
        "\"\"\"\n",
        "\n",
        "testpic     = \"./dog1.jpg\"\n",
        "keras_param = \"./cnn.h5\"\n",
        "\n",
        "def load_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.convert('RGB')\n",
        "    # 学習時に、(64, 64, 3)で学習したので、画像の縦・横は今回 変数imsizeの(64, 64)にリサイズします。\n",
        "    img = img.resize(imsize)\n",
        "    # 画像データをnumpy配列の形式に変更\n",
        "    img = np.asarray(img)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "model = load_model(keras_param)\n",
        "img = load_image(testpic)\n",
        "prd = model.predict(np.array([img]))\n",
        "print(prd) # 精度の表示\n",
        "prelabel = np.argmax(prd, axis=1)\n",
        "if prelabel == 0:\n",
        "    print(\">>> 犬\")\n",
        "elif prelabel == 1:\n",
        "    print(\">>> 猫\")"
      ],
      "metadata": {
        "id": "-duwr9YAOYDD",
        "outputId": "0f46ba5f-60af-46c9-f466-c0febef7faad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.9999797e-01 2.0808734e-06]]\n",
            ">>> 犬\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b43HhkJ4DaWV"
      },
      "source": [
        ""
      ]
    }
  ]
}